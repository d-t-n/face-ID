{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face identification\n",
    "## Pytorch and OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x1e90c80b6c8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Import libraries\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "                                                 \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "torch.set_printoptions(linewidth = 120)\n",
    "torch.set_grad_enabled(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## collects images with webcam in 2 folders - alpha and beta\n",
    "\n",
    "def collect_and_save(foldername, count):\n",
    "    \n",
    "    os.mkdir(foldername)\n",
    "    \n",
    "    faces_rect = ()\n",
    "    \n",
    "    def detect_faces(cascade, test_image):\n",
    "        global counter \n",
    "        global faces_rect\n",
    "        gray_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)   # opencv to detect images in gray\n",
    "\n",
    "        faces_rect = cascade.detectMultiScale(gray_image)  # classifier \n",
    "\n",
    "        for (x, y, w, h) in faces_rect:\n",
    "            cv2.rectangle(gray_image, (x - 20, y-20), (x+w+ 20, y+h+70), (255, 0, 0), 8)   ## slight padding added to make sure the full face comes in \n",
    "            #cv2.putText(gray_image, 'Your Face', (x, y-10), cv2.FONT_HERSHEY_DUPLEX, 0.9, (36,255,12), 2)\n",
    "        if faces_rect != ():\n",
    "\n",
    "                fmt_name = foldername + \"/\" + str(faces_rect) +\".png\"\n",
    "\n",
    "                crop_img = gray_image[y:y+h+70, x-20 :x+w +20]     ## added some padding  as + 20 and - 70\n",
    "\n",
    "                cv2.imwrite(fmt_name,crop_img)\n",
    "                \n",
    "               ## crop\n",
    "        return gray_image\n",
    "\n",
    "    def feed(count):    ## q to quit \n",
    "        \n",
    "        print (\" will collect images for face now -- \")\n",
    "        print (\"\")\n",
    "        input(\"press enter to continue --\")\n",
    "        \n",
    "        counter = 0 \n",
    "        global faces_rect\n",
    "        haar_cascade_face = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalcatface.xml')\n",
    "\n",
    "        ## CAMERA CAPTURE FEED \n",
    "        cap = cv2.VideoCapture(0)\n",
    "\n",
    "        while counter < count:                    \n",
    "            # Capture frame-by-frame\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            frame = detect_faces(haar_cascade_face, frame)\n",
    "            \n",
    "            if faces_rect != ():\n",
    "                counter+= 1\n",
    "                print (\"collected \", faces_rect,\".png\")\n",
    "                \n",
    "            cv2.imshow('frame', frame)\n",
    "            \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):    ## press q to quit \n",
    "                break\n",
    "\n",
    "        # When done, release the capture\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    feed(count)\n",
    "    \n",
    "    print (\"\")\n",
    "    print (count, \" photos saved in  -- \", foldername)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Cannot create a file when that file already exists: 'alpha'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-1412262c5065>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcollect_and_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"alpha\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcollect_and_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beta\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-0100366a66b6>\u001b[0m in \u001b[0;36mcollect_and_save\u001b[1;34m(foldername, count)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcollect_and_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfoldername\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfoldername\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mfaces_rect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Cannot create a file when that file already exists: 'alpha'"
     ]
    }
   ],
   "source": [
    "collect_and_save(\"alpha\", 50)\n",
    "\n",
    "collect_and_save(\"beta\", 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_processor(): \n",
    "    \n",
    "    os.mkdir(\"numpy\")\n",
    "    \n",
    "    print (\"processing images now ...\")\n",
    "    \n",
    "    def load_images_from_folder(folder):\n",
    "        images = []\n",
    "        for filename in os.listdir(folder):\n",
    "            path = folder +\"/\"+ filename\n",
    "\n",
    "            im = Image.open(path)\n",
    "\n",
    "            im = im.convert('L')\n",
    "            \n",
    "            # grayscale because sneakyboi was born colorblind\n",
    "\n",
    "            images.append(im)\n",
    "        return images\n",
    "\n",
    "\n",
    "    def convert_to_numpy(arr, vector):\n",
    "        np_arr = []\n",
    "        for p in range (len(arr)):\n",
    "            mario =  [np.array(arr[p]), vector]\n",
    "            np_arr.append(mario)\n",
    "        return np_arr\n",
    "\n",
    "    def normalise(arr, width, height):  ## resize and standardise\n",
    "        arr_copy = arr\n",
    "        for p in range (len(arr)):\n",
    "            doofus = arr[p]\n",
    "            doofus = doofus.resize((width, height), Image.ANTIALIAS)\n",
    "            arr_copy[p]= doofus\n",
    "        return arr_copy\n",
    "\n",
    "\n",
    "    def save(arr, name):\n",
    "        fmt_name  = \"numpy/\" + name   # numpy array saver\n",
    "        np.save(fmt_name, arr)\n",
    "\n",
    "        print (\"saved -- \", fmt_name)\n",
    "\n",
    "    def cvt_raw_data():\n",
    "\n",
    "        alpha_arr = load_images_from_folder(\"alpha\")\n",
    "        beta_arr = load_images_from_folder(\"beta\")\n",
    "\n",
    "\n",
    "        alpha_norm = normalise(alpha_arr , 200, 200)\n",
    "        beta_norm = normalise(beta_arr , 200, 200)\n",
    "\n",
    "\n",
    "        alpha_final = convert_to_numpy(alpha_norm, [0])\n",
    "        beta_final = convert_to_numpy(beta_norm, [1])\n",
    "\n",
    "\n",
    "        save(alpha_final, \"alpha_final\")\n",
    "        save(beta_final, \"beta_final\")\n",
    "        \n",
    "    cvt_raw_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing images now ...\n",
      "saved --  numpy/alpha_final\n",
      "saved --  numpy/beta_final\n"
     ]
    }
   ],
   "source": [
    "img_processor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[255, 255, 250, ..., 255, 254, 255],\n",
      "       [255, 255, 250, ..., 255, 254, 255],\n",
      "       [255, 255, 250, ..., 255, 254, 255],\n",
      "       ...,\n",
      "       [255, 255, 255, ..., 255, 255, 255],\n",
      "       [255, 255, 255, ..., 255, 255, 255],\n",
      "       [255, 255, 255, ..., 255, 255, 255]], dtype=uint8)\n",
      " list([0])]\n"
     ]
    }
   ],
   "source": [
    "foo = np.array(np.load(\"numpy/alpha_final.npy\"))   # checking a sample frame \n",
    "\n",
    "print (foo[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalise_data():\n",
    "    \n",
    "    \n",
    "    def preprocess( arr1, arr2 ):\n",
    "\n",
    "        alpha = np.array(np.load(arr1))\n",
    "        beta = np.array(np.load(arr2))\n",
    "\n",
    "        gamma = np.concatenate((alpha, beta), axis = 0)  # concatenates - as the word is sugesting \n",
    "        \n",
    "\n",
    "        np.random.shuffle(gamma)\n",
    "\n",
    "        np.save (\"numpy/binary_shuffled.npy\", gamma)\n",
    "        print (\"final array has been saved as --   binary_shuffled.npy  - in folder -- numpy\" )\n",
    "\n",
    "\n",
    "    preprocess(\"numpy/alpha_final.npy\", \"numpy/beta_final.npy\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final array has been saved as --   binary_shuffled.npy  - in folder -- numpy\n"
     ]
    }
   ],
   "source": [
    "finalise_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################  ALL FINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chug_to_tensor(images,labels):\n",
    "    images = torch.from_numpy(images)\n",
    "    labels = torch.tensor(labels)\n",
    "    images = images.unsqueeze(0)\n",
    "    images = images.unsqueeze(0)\n",
    " \n",
    "    images = images.type(torch.float32)\n",
    "\n",
    "    return (images,labels)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, 5)\n",
    "        \n",
    "        # in_channels = 1, out_channels = 10 kernel_size = 5 (kernel is the filter thingy )\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(4, 4)   ## changed from (3,3) to (4,4)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(10, 20, 5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(2420, 125)       # linear starts \n",
    "        self.fc2 = nn.Linear(125, 80)\n",
    "        self.fc3 = nn.Linear(80, 2)   ## op\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 2420)                   # reshape thingy\n",
    "        x = F.relu(self.fc1(x))  \n",
    "        \n",
    "## DO NOT USE SOFTMAX AND CROSSENTROPY TOGETHER, USE relu FOR CrossEntropyLoss\n",
    "\n",
    "        x = F.relu(self.fc2(x))\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "facenet = Net()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_arr = []\n",
    "epoch_arr = []\n",
    "\n",
    "\n",
    "def train_loop(epochs):\n",
    "    \n",
    "    foo = np.array(np.load(\"numpy/binary_shuffled.npy\"))\n",
    "        \n",
    "    peanut = foo\n",
    "    \n",
    "    \n",
    "    global loss_arr\n",
    "    \n",
    "    global epoch_arr \n",
    "        \n",
    "    \n",
    "    optimizer = optim.Adam(facenet.parameters(), lr = 0.001)\n",
    "    \n",
    "    for m in range (epochs):\n",
    "\n",
    "\n",
    "        epoch_loss = 0\n",
    "\n",
    "        single_batch = next(iter(peanut))\n",
    "\n",
    "        for single_batch in peanut:\n",
    "\n",
    "            image, label = single_batch\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            image,label = chug_to_tensor(image, label)\n",
    "\n",
    "            pred = facenet(image).squeeze(1)\n",
    "            \n",
    "           \n",
    "\n",
    "            loss = F.cross_entropy(pred,label)    # pain to fix if messed up\n",
    "\n",
    "            loss.backward()   #backprop\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss\n",
    "            \n",
    "            \n",
    "        print ( m + 1, \" epoch    \", \"loss  - \", epoch_loss.item() )\n",
    "        \n",
    "        threshold = torch.tensor([0.1])\n",
    "        \n",
    "        if torch.gt(threshold, epoch_loss):     ## prevent overtraining\n",
    "            \n",
    "            print (\"----\")\n",
    "            print (' overtraining prevented, loss was too low ')\n",
    "            print (\"----\")\n",
    "            break\n",
    "         \n",
    "    \n",
    "        epoch_loss = epoch_loss.item()\n",
    "\n",
    "        loss_arr.append(epoch_loss)\n",
    "        epoch_arr.append(m+1)\n",
    "            \n",
    "\n",
    "        \n",
    "    \n",
    "        \n",
    "    \n",
    "        \n",
    "    print (\"training  done  \")  \n",
    "\n",
    "\n",
    "def train_main():\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    mario = int(input(\"enter number of epochs > 30 would be enough :  \"))\n",
    "    train_loop(mario)\n",
    "    \n",
    "def show_analysis():\n",
    "    \n",
    "    global loss_arr\n",
    "    global epoch_arr\n",
    "    def show_plot(epoch_arr, loss_arr):\n",
    "        #print (loss_arr)\n",
    "        plt.plot(epoch_arr, loss_arr, linewidth = 1.0 )\n",
    "        plt.ylabel(\" loss \")\n",
    "        \n",
    "        plt.xlabel(\" epochs \")\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        \n",
    "    show_plot(epoch_arr, loss_arr)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter number of epochs > 30 would be enough :  30\n",
      "1  epoch     loss  -  102.99671936035156\n",
      "2  epoch     loss  -  29.24257469177246\n",
      "3  epoch     loss  -  27.46967124938965\n"
     ]
    }
   ],
   "source": [
    "train_main()\n",
    "\n",
    "show_analysis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tensor(images):\n",
    "    \n",
    "    images = torch.from_numpy(images)\n",
    "    \n",
    "    images = images.unsqueeze(0)\n",
    "    images = images.unsqueeze(0)\n",
    " \n",
    "    images = images.type(torch.float32)\n",
    "\n",
    "    return (images)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "faces_rect = ()\n",
    "def detect_faces(cascade, test_image):\n",
    "\n",
    "    global faces_rect\n",
    "    gray_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)   # opencv detects stuff in gray\n",
    "\n",
    "    faces_rect = cascade.detectMultiScale(gray_image)  # classifier \n",
    "   \n",
    "    \n",
    "    \n",
    "    for (x, y, w, h) in faces_rect:\n",
    "        \n",
    "        cv2.rectangle(gray_image, (x - 20, y-20), (x+w+ 20, y+h+70), (255, 0, 0), 8)   \n",
    "        #cv2.putText(gray_image, 'Your Face', (x, y-10), cv2.FONT_HERSHEY_DUPLEX, 0.9, (36,255,12), 2)\n",
    "        ## slight padding added to make sure the full face comes in \n",
    "        \n",
    "    if faces_rect != ():\n",
    "            print (\"face !\")\n",
    "            crop_img = gray_image[y:y+h+70, x-20 :x+w +20]\n",
    "            \n",
    "            \n",
    "#             print (crop_img)\n",
    "            \n",
    "            img = Image.fromarray(crop_img)\n",
    "\n",
    "            img = img.resize((200, 200), Image.ANTIALIAS)  # resize\n",
    "    \n",
    "           \n",
    "\n",
    "            im = np.array(img)\n",
    "\n",
    "\n",
    "            im = torch.from_numpy(im)\n",
    "            im = im.unsqueeze(0)\n",
    "            im = im.unsqueeze(0)      # convert to 4d torch tensor\n",
    "\n",
    "            im = im.float()\n",
    "\n",
    "            res = facenet(im)\n",
    "            \n",
    "            print(res)\n",
    "            \n",
    "            prediction = res.argmax()\n",
    "            print (\"prediction  -------------------------- \", prediction)\n",
    "            \n",
    "        \n",
    "           \n",
    "    return gray_image\n",
    "\n",
    "\n",
    "\n",
    "def cam_feed():    ## q to quit \n",
    "    global faces_rect\n",
    "    haar_cascade_face = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalcatface.xml')\n",
    "\n",
    "    ## CAMERA CAPTURE FEED \n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while(True):                    \n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "\n",
    "        \n",
    "        frame = detect_faces(haar_cascade_face, frame)\n",
    " \n",
    "        \n",
    "        \n",
    "       \n",
    "        cv2.imshow('frame', frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # When done, release the capture\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    \n",
    "cam_feed()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## initially I was showing anant's face to which it showed the prediction as 0 \n",
    "\n",
    "## and then I showed my face to which the prediction came to be 1 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
